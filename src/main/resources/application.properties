# ==================================================================================================================
# 						APP CONFIG
# ==================================================================================================================
server.address=0.0.0.0
server.port=8084

# ==================================================================================================================
# 					LOGGING CONFIG - SPRING BOOT
# ==================================================================================================================
# ANALISE KEYCLOACK
logging.level.org.springframework.security=INFO 
logging.pattern.console=%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n
logging.level.org.springframework=INFO
logging.level.root=INFO

# reduzir ruído do driver Mongo
logging.level.org.mongodb.driver.cluster=ERROR
logging.level.org.mongodb.driver.connection=ERROR
logging.level.org.mongodb.driver.client=ERROR

# ==================================================================================================================
# 					DATABASE - SPRING BOOT (PostgreSQL)
# ==================================================================================================================
spring.datasource.url=jdbc:postgresql://localhost:5432/appdb
spring.datasource.username=appuser
spring.datasource.password=apppass
spring.datasource.driver-class-name=org.postgresql.Driver
spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.hibernate.ddl-auto=none
spring.jpa.show-sql=false
spring.jpa.open-in-view=false
spring.jpa.properties.hibernate.format_sql=false
# evita createClob
spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation=true
# Inicialização via scripts SQL
spring.sql.init.mode=always
spring.sql.init.encoding=UTF-8

# ==================================================================================================================
# 						KAFKA - BROKER
# ==================================================================================================================
# Endereco do(s) broker(s)
spring.kafka.bootstrap-servers=${SPRING_KAFKA_BOOTSTRAP_SERVERS:localhost:29092}

# ==================================================================================================================
# 						KAFKA - TOPICO / PUBLISH
# ==================================================================================================================
# Nome do topico de finalizacao de pedidos
app.kafka.topic.order-finalized=orders.finalized
app.kafka.topic.audit-log-event=audit-log-event

# Producer (String key + JSON value)
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer

# Inclui type headers (FQN da classe no payload necessario para desserializacao no consumer)
spring.kafka.producer.properties.spring.json.add.type.headers=true

# ==================================================================================================================
# 						KAFKA - CONSUMER / SUBSCRIBE
# ==================================================================================================================
# ATENÇÃO!!! Cada aplicativo que precisa receber a mesma mensagem DEVE ter um group-id diferente
spring.kafka.consumer.group-id=app-audit

# Reinicia leitura do inicio caso nao haja offset salvo
spring.kafka.consumer.auto-offset-reset=earliest

# Consumer (String key + JSON value)
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer

# Confia nos type headers enviados pelo Producer
spring.kafka.consumer.properties.spring.json.use.type.headers=true

# Pacote(s) permitido(s) para desserializar os eventos
spring.kafka.consumer.properties.spring.json.trusted.packages=br.com.ramiralvesmelo.util.message.event

# ==================================================================================================================
# 						KAFKA - LISTENER / ADMIN
# ==================================================================================================================
# Inicia automaticamente os listeners
spring.kafka.listener.auto-startup=true

# Nao cria topicos automaticamente (p/ producao)
spring.kafka.admin.auto-create=false

# ==================================================================================================================
# 						KEYCLOACK - OIDC / Resource Server
# ==================================================================================================================
# === Resource Server JWT (Spring Security valida o token do Keycloak) ===
spring.security.oauth2.resourceserver.jwt.issuer-uri=http://keycloak:8081/realms/app-demo
# expõe somente health (e info se quiser)
management.endpoints.web.exposure.include=health
# (opcional) ver detalhes no /actuator/health
management.endpoint.health.show-details=never
# (opcional) liveness/readiness
management.endpoint.health.probes.enabled=true
# caminho padrão é "/actuator"
# management.endpoints.web.base-path=/actuator

# ==================================================================================================================
#                                      MongoDB
# ==================================================================================================================
# URI de conexão (com usuário/senha caso configurados no docker-compose)
spring.data.mongodb.uri=mongodb://mongoadmin:mongopass@localhost:27017/auditdb?authSource=admin

# Nome do banco de dados
spring.data.mongodb.database=auditdb

# Habilita criação automática de índices definidos nas entidades @Document
spring.data.mongodb.auto-index-creation=true

# Pool de conexões
spring.data.mongodb.socket-timeout=3000
spring.data.mongodb.connect-timeout=3000

# Logs de queries MongoDB (útil em dev)
logging.level.org.springframework.data.mongodb.core.MongoTemplate=DEBUG
